{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "123d6b15-e676-45d6-87d3-9f75e5a7021c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.6.1)\n",
      "Requirement already satisfied: httpx>=0.27 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ollama) (2.12.5)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx>=0.27->ollama) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic>=2.9->ollama) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic>=2.9->ollama) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic>=2.9->ollama) (0.4.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from anyio->httpx>=0.27->ollama) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a1992198-18fa-40cf-88a7-ec8a538aea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ollama\n",
    "\n",
    "# response = ollama.chat(\n",
    "#     model='gemma3:1b',\n",
    "#     messages=[\n",
    "#         {'role': 'user', 'content': prompt}\n",
    "#         ]\n",
    "# )\n",
    "\n",
    "# print(response['message']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18fe1a18-0ee5-44e6-8ccc-0eb4d4191c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.52.1)\n",
      "Requirement already satisfied: ollama in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.6.1)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from streamlit) (6.2.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from streamlit) (8.3.1)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from streamlit) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from streamlit) (2.3.1)\n",
      "Requirement already satisfied: pillow<13,>=7.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from streamlit) (11.3.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from streamlit) (6.33.2)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from streamlit) (22.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from streamlit) (2.32.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from streamlit) (4.14.1)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from streamlit) (3.1.45)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from streamlit) (6.5.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.24.0)\n",
      "Requirement already satisfied: narwhals>=1.27.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.13.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
      "Requirement already satisfied: httpx>=0.27 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ollama) (2.12.5)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.26.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic>=2.9->ollama) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic>=2.9->ollama) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from anyio->httpx>=0.27->ollama) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad804e3d-1c17-47b8-b7a9-cb3e596daefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import json\n",
    "import ollama\n",
    "import os\n",
    "import re\n",
    "\n",
    "TICKET_FILE = \"tickets.json\"\n",
    "MEMORY_FILE = \"memory.json\"\n",
    "\n",
    "\n",
    "# ---------- Load JSON ----------\n",
    "def load_tickets():\n",
    "    if not os.path.exists(TICKET_FILE):\n",
    "        return []\n",
    "    with open(TICKET_FILE, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# ---------- Save JSON ----------\n",
    "def save_tickets(tickets):\n",
    "    with open(TICKET_FILE, \"w\") as f:\n",
    "        json.dump(tickets, f, indent=2)\n",
    "\n",
    "# ---------- Next Ticket Number ----------\n",
    "def get_next_ticket_no(tickets):\n",
    "    if not tickets:\n",
    "        return \"TICKET-0001\"\n",
    "    last = tickets[-1][\"ticket_no\"]\n",
    "    number = int(last.split(\"-\")[1])\n",
    "    return f\"TICKET-{number+1:04d}\"\n",
    "\n",
    "# ---------- FIELD SCORE ----------\n",
    "def field_score(field_value: str, description: str) -> float:\n",
    "    if not field_value or field_value.lower() == \"unknown\":\n",
    "        return 0.3\n",
    "\n",
    "    desc = description.lower()\n",
    "    fv = field_value.lower()\n",
    "\n",
    "    if re.search(r\"\\b\" + re.escape(fv) + r\"\\b\", desc):\n",
    "        return 1.0  # exact match\n",
    "\n",
    "    return 0.7  # inferred\n",
    "\n",
    "\n",
    "# ---------- CONFIDENCE COMPUTATION ----------\n",
    "def compute_confidence(issue_type, severity, affected_system, description):\n",
    "    w_issue = 0.33\n",
    "    w_sev = 0.33\n",
    "    w_sys = 0.33\n",
    "\n",
    "    s_issue = field_score(issue_type, description)\n",
    "    s_sev = field_score(severity, description)\n",
    "    s_sys = field_score(affected_system, description)\n",
    "\n",
    "    conf = (s_issue * w_issue + s_sev * w_sev + s_sys * w_sys) * 100\n",
    "\n",
    "    \n",
    "    if (\n",
    "        issue_type\n",
    "        and affected_system\n",
    "        and issue_type.lower() == affected_system.lower()\n",
    "    ):\n",
    "        conf = min(conf, 70)\n",
    "\n",
    "    # Normalize\n",
    "    if conf < 40:\n",
    "        conf = 40\n",
    "    if conf > 95:\n",
    "        conf = 95\n",
    "\n",
    "    return round(conf)\n",
    "\n",
    "\n",
    "# ---------- GENERATE FIX ----------\n",
    "def generate_proposed_fix(description):\n",
    "    prompt = f\"\"\"\n",
    "Generate a short practical fix for this issue. \n",
    "Return ONLY the fix sentence. No JSON.\n",
    "\n",
    "Issue:\n",
    "{description}\n",
    "\"\"\"\n",
    "    response = ollama.chat(\n",
    "        model='gemma3:1b',\n",
    "        messages=[{'role': 'user', 'content': prompt}]\n",
    "    )\n",
    "    return response[\"message\"][\"content\"].strip()\n",
    "\n",
    "\n",
    "# ---------- AI Analyzer ----------\n",
    "def analyze_ticket(description):\n",
    "    prompt = f\"\"\"\n",
    "You are an information extraction system.\n",
    "\n",
    "RULES:\n",
    "1. Infer severity, issue_type, and affected_system from the text when possible.\n",
    "2. If truly not identifiable, set the value to \"unknown\".\n",
    "\n",
    "--------------- EXTRACTION RULES ---------------\n",
    "1. Extract the following fields only from the given text:\n",
    "   - issue_type: What type of problem is described?\n",
    "   - severity: low, medium, high, critical (or \"unknown\" if not clearly stated)\n",
    "   - affected_system: The system or component affected\n",
    "   \n",
    "Inference rules:\n",
    "- Infer values only when the text clearly implies them.\n",
    "- Do NOT guess. If unclear, set \"unknown\".\n",
    "- If severity keyword is not available in the description make the severity portion output in json as \"unknown\"\n",
    "\n",
    "Return JSON ONLY.\n",
    "\n",
    "JSON FORMAT:\n",
    "{{\n",
    "  \"issue_type\": \"\",\n",
    "  \"severity\": \"\",\n",
    "  \"affected_system\": \"\"\n",
    "}}\n",
    "\n",
    "TEXT:\n",
    "\"{description}\"\n",
    "\"\"\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model='gemma3:1b',\n",
    "        messages=[{'role':'user','content':prompt}]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        content = response[\"message\"][\"content\"]\n",
    "        json_start = content.find(\"{\")\n",
    "        json_end = content.rfind(\"}\") + 1\n",
    "        extracted = json.loads(content[json_start:json_end])\n",
    "    except:\n",
    "        extracted = {\n",
    "            \"issue_type\": \"unknown\",\n",
    "            \"severity\": \"unknown\",\n",
    "            \"affected_system\": \"unknown\",\n",
    "        }\n",
    "\n",
    "    # --- Compute confidence using Python function ---\n",
    "    conf = compute_confidence(\n",
    "        extracted.get(\"issue_type\", \"\"),\n",
    "        extracted.get(\"severity\", \"\"),\n",
    "        extracted.get(\"affected_system\", \"\"),\n",
    "        description,\n",
    "    )\n",
    "\n",
    "    # Add confidence\n",
    "    extracted[\"confidence\"] = conf\n",
    "\n",
    "    # Add propose fix if confidence â‰¥ 85\n",
    "    if conf >= 85:\n",
    "        extracted[\"propose_fix\"] = generate_proposed_fix(description)\n",
    "    else:\n",
    "        extracted[\"propose_fix\"] = \"none\"\n",
    "\n",
    "    return extracted\n",
    "\n",
    "\n",
    "# ---------- AUTO PROCESS OPEN TICKETS ----------\n",
    "def auto_process_open_tickets():\n",
    "    tickets = load_tickets()\n",
    "    changed = False\n",
    "\n",
    "    for t in tickets:\n",
    "        if t[\"status\"] == \"open\":\n",
    "            analysis = analyze_ticket(t[\"description\"])\n",
    "            t[\"ai_analysis\"] = analysis\n",
    "\n",
    "            if analysis[\"confidence\"] >= 85:\n",
    "                t[\"status\"] = \"closed\"\n",
    "            else:\n",
    "                t[\"status\"] = \"need review\"\n",
    "\n",
    "            changed = True\n",
    "\n",
    "    if changed:\n",
    "        save_tickets(tickets)\n",
    "\n",
    "def parse_search_query(query):\n",
    "    prompt = f\"\"\"\n",
    "Extract ONLY these two fields from the search query:\n",
    "\n",
    "1. status â†’ one of: \"open\", \"closed\", \"need review\"\n",
    "2. severity â†’ one of: \"low\", \"medium\", \"high\", \"critical\"\n",
    "\n",
    "RULES:\n",
    "- If field is not mentioned, return \"none\".\n",
    "- Do NOT infer anything.\n",
    "- Do NOT extract any other field.\n",
    "- Return ONLY the following JSON:\n",
    "\n",
    "{{\n",
    "  \"status\": \"\",\n",
    "  \"severity\": \"\"\n",
    "}}\n",
    "\n",
    "QUERY:\n",
    "\"{query}\"\n",
    "\"\"\"\n",
    "    response = ollama.chat(\n",
    "        model=\"gemma3:1b\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        text = response[\"message\"][\"content\"]\n",
    "        js = json.loads(text[text.find(\"{\"): text.rfind(\"}\") + 1])\n",
    "        return js\n",
    "    except:\n",
    "        return {\"status\": \"none\", \"severity\": \"none\"}\n",
    "\n",
    "\n",
    "def filter_tickets(tickets, status, severity):\n",
    "    results = []\n",
    "    for t in tickets:\n",
    "        ai = t.get(\"ai_analysis\", {})\n",
    "        if status != \"none\" and t[\"status\"] != status:\n",
    "            continue\n",
    "        if severity != \"none\" and ai.get(\"severity\") != severity:\n",
    "            continue\n",
    "        results.append(t)\n",
    "    return results\n",
    "\n",
    "def load_memory():\n",
    "    if not os.path.exists(MEMORY_FILE):\n",
    "        return []\n",
    "    with open(MEMORY_FILE, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_memory(memory):\n",
    "    with open(MEMORY_FILE, \"w\") as f:\n",
    "        json.dump(memory, f, indent=2)\n",
    "\n",
    "\n",
    "\n",
    "# ---------- STREAMLIT UI ----------\n",
    "st.title(\"Automated Ticketing System\")\n",
    "\n",
    "auto_process_open_tickets()\n",
    "\n",
    "st.subheader(\"Create a New Ticket\")\n",
    "user_input = st.text_input(\"Enter new ticket description:\")\n",
    "\n",
    "if st.button(\"Create Ticket\"):\n",
    "    if not user_input.strip():\n",
    "        st.error(\"Please enter a ticket description.\")\n",
    "    else:\n",
    "        tickets = load_tickets()\n",
    "        new_no = get_next_ticket_no(tickets)\n",
    "\n",
    "        new_ticket = {\n",
    "            \"ticket_no\": new_no,\n",
    "            \"description\": user_input,\n",
    "            \"status\": \"open\"\n",
    "        }\n",
    "\n",
    "        tickets.append(new_ticket)\n",
    "        save_tickets(tickets)\n",
    "\n",
    "        auto_process_open_tickets()\n",
    "\n",
    "        st.success(f\"Ticket {new_no} created and processed!\")\n",
    "\n",
    "st.subheader(\"Search Tickets (Natural Language Query)\")\n",
    "\n",
    "# ---- SESSION STATE INIT ----\n",
    "if \"search_results\" not in st.session_state:\n",
    "    st.session_state.search_results = []\n",
    "if \"selected_ticket\" not in st.session_state:\n",
    "    st.session_state.selected_ticket = None\n",
    "if \"search_performed\" not in st.session_state:\n",
    "    st.session_state.search_performed = False\n",
    "\n",
    "search_text = st.text_input(\"Ask something like: 'show me need review medium severity tickets'\")\n",
    "\n",
    "# ---- SEARCH BUTTON ----\n",
    "if st.button(\"Search\"):\n",
    "    if not search_text.strip():\n",
    "        st.error(\"Please enter a query.\")\n",
    "    else:\n",
    "        filters = parse_search_query(search_text)\n",
    "        tickets = load_tickets()\n",
    "\n",
    "        st.session_state.search_results = filter_tickets(\n",
    "            tickets,\n",
    "            filters[\"status\"],\n",
    "            filters[\"severity\"]\n",
    "        )\n",
    "        st.session_state.selected_ticket = None\n",
    "        st.session_state.search_performed = True   # <-- only now we allow results/warnings\n",
    "\n",
    "# ---- DISPLAY RESULTS ----\n",
    "results = st.session_state.search_results\n",
    "\n",
    "if st.session_state.search_performed:\n",
    "    if results:\n",
    "        st.write(\"### Search Results\")\n",
    "\n",
    "        labels = [f\"{t['ticket_no']}: {t['description'][:50]}...\" for t in results]\n",
    "\n",
    "        selected_label = st.radio(\n",
    "            \"Select a ticket to view details:\",\n",
    "            labels,\n",
    "            key=\"ticket_radio\"\n",
    "        )\n",
    "\n",
    "        ticket_no = selected_label.split(\":\")[0]\n",
    "\n",
    "        st.session_state.selected_ticket = next(\n",
    "            t for t in results if t[\"ticket_no\"] == ticket_no\n",
    "        )\n",
    "\n",
    "        st.write(\"### Ticket Details\")\n",
    "        st.json(st.session_state.selected_ticket)\n",
    "\n",
    "    else:\n",
    "        st.warning(\"No tickets found matching your filters.\")\n",
    "\n",
    "\n",
    "#   HUMAN REVIEW & MANUAL CLOSURE\n",
    "\n",
    "st.subheader(\"Manual Ticket Closure (Need Review Only)\")\n",
    "\n",
    "ticket_to_close = st.text_input(\"Enter Ticket Number to Close\")\n",
    "resolution_notes = st.text_area(\"Enter Human Resolution Notes\")\n",
    "\n",
    "if st.button(\"Close Ticket Manually\"):\n",
    "    if not ticket_to_close.strip():\n",
    "        st.error(\"Please enter a ticket number.\")\n",
    "    elif not resolution_notes.strip():\n",
    "        st.error(\"Please enter resolution notes.\")\n",
    "    else:\n",
    "        tickets = load_tickets()\n",
    "        found = False\n",
    "\n",
    "        for t in tickets:\n",
    "            if t[\"ticket_no\"].strip().upper() == ticket_to_close.strip().upper():\n",
    "                if t[\"status\"] != \"need review\":\n",
    "                    st.error(\"This ticket is not in 'need review' state.\")\n",
    "                    break\n",
    "\n",
    "                t[\"status\"] = \"closed\"\n",
    "                t[\"human_resolution\"] = resolution_notes\n",
    "                found = True\n",
    "                save_tickets(tickets)\n",
    "\n",
    "                # Save to memory.json\n",
    "                memory = load_memory()\n",
    "                memory.append({\n",
    "                    \"ticket_no\": ticket_to_close,\n",
    "                    \"resolution\": resolution_notes,\n",
    "                    \"approved_by_human\": True\n",
    "                })\n",
    "                save_memory(memory)\n",
    "\n",
    "                st.success(f\"Ticket {ticket_to_close} has been manually closed.\")\n",
    "                st.session_state[\"ticket_to_close\"] = \"\"\n",
    "                st.session_state[\"resolution_notes\"] = \"\"\n",
    "\n",
    "                # Clear selected ticket details\n",
    "                st.session_state.selected_ticket = None\n",
    "                \n",
    "                break\n",
    "\n",
    "        if not found:\n",
    "            st.error(\"Ticket not found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0476dbf0-14f5-44f1-b6ca-23bdaec5a5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://10.111.27.139:8501\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://152.57.8.216:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py --server.headless true --server.port 8501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a12365-8150-4ce2-915d-65953cd38998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c640d9-71d9-45e0-8f01-a35a97ad1f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4717552c-0666-4dfe-a5d0-460780146058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3068398-5e2f-401a-aede-088994959ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f102a8c-0869-474a-a9fa-08dfabd185d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c66d879-6015-411b-b980-27990521a71e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da518640-7e2b-4117-9298-8b6c4a22839c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13608557-17b4-4cd3-875c-fe38764ac8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731769ef-f04c-442c-8522-eba0bc73e1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31b4cbc-b982-4857-b2f2-fafb860a9d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f37f33a-aa5a-425e-94d9-08f152adc76a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c1f257-b7ed-4186-9beb-4eb455b937ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec752d78-e2c0-48a4-8074-c8049e69d98a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5438f91-5c36-4f81-8cac-23e7d911261d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import json\n",
    "import ollama\n",
    "import os\n",
    "\n",
    "TICKET_FILE = \"tickets.json\"\n",
    "\n",
    "# ---------- Load JSON ----------\n",
    "def load_tickets():\n",
    "    if not os.path.exists(TICKET_FILE):\n",
    "        return []\n",
    "    with open(TICKET_FILE, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# ---------- Save JSON ----------\n",
    "def save_tickets(tickets):\n",
    "    with open(TICKET_FILE, \"w\") as f:\n",
    "        json.dump(tickets, f, indent=2)\n",
    "\n",
    "# ---------- Next Ticket Number ----------\n",
    "def get_next_ticket_no(tickets):\n",
    "    if not tickets:\n",
    "        return \"TICKET-0001\"\n",
    "    last = tickets[-1][\"ticket_no\"]\n",
    "    number = int(last.split(\"-\")[1])\n",
    "    return f\"TICKET-{number+1:04d}\"\n",
    "\n",
    "# ---------- AI Analyzer (FINAL FIXED VERSION) ----------\n",
    "def analyze_ticket(description):\n",
    "    prompt = f\"\"\"\n",
    "You are an information extraction system.\n",
    "\n",
    "RULES:\n",
    "1. Infer severity, issue_type, and affected_system from the text when possible.\n",
    "2. If truly not identifiable, set the value to \"unknown\".\n",
    "\n",
    "--------------- EXTRACTION RULES ---------------\n",
    "1. Extract the following fields only from the given text:\n",
    "   - issue_type: What type of problem is described? (bug, error, incident, service request, etc.)\n",
    "   - severity: low, medium, high, critical (or \"unknown\" if not clearly stated)\n",
    "   - affected_system: The system or component affected (CRM, ERP, Email System, Database, etc.)\n",
    "   \n",
    "Inference rules:\n",
    "- Infer values only when the text clearly implies them.\n",
    "- Do NOT guess. If unclear, set \"unknown\".\n",
    "\n",
    "3. If the description is vague, indirect, or ambiguous:\n",
    "   - You may infer the field, but mark confidence lower.\n",
    "\n",
    "CONFIDENCE RULE:\n",
    "- Start with confidence = 90.\n",
    "- 90 â†’ All fields are clear and explicit (no assumptions needed).\n",
    "- 70 â†’ All fields can be extracted but the description is vague OR requires inference.\n",
    "- 60 â†’ At least one field is \"unknown\".\n",
    "- 40 â†’ Description is too vague to extract fields reliably.\n",
    "- If severity keyword is not available in the description make the severity portion \"unknown\" and lower confidence to 70\n",
    "\n",
    "Return ONLY valid JSON. No explanation, no markdown.\n",
    "\n",
    "JSON FORMAT:\n",
    "{{\n",
    "  \"issue_type\": \"\",\n",
    "  \"severity\": \"\",\n",
    "  \"affected_system\": \"\",\n",
    "  \"confidence\": 0\n",
    "}}\n",
    "\n",
    "TEXT TO ANALYZE:\n",
    "\"{description}\"\n",
    "\"\"\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model='gemma3:1b',\n",
    "        messages=[{'role': 'user', 'content': prompt}]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        content = response[\"message\"][\"content\"]\n",
    "\n",
    "        # Extract JSON portion only\n",
    "        json_start = content.find(\"{\")\n",
    "        json_end = content.rfind(\"}\") + 1\n",
    "        json_text = content[json_start:json_end]\n",
    "\n",
    "        return json.loads(json_text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"JSON Parse Error:\", e)\n",
    "        print(\"MODEL OUTPUT:\", response[\"message\"][\"content\"])\n",
    "        return {\n",
    "            \"issue_type\": \"unknown\",\n",
    "            \"severity\": \"unknown\",\n",
    "            \"affected_system\": \"unknown\",\n",
    "            \"confidence\": 0\n",
    "        }\n",
    "\n",
    "# ---------- AUTO PROCESS OPEN TICKETS ----------\n",
    "def auto_process_open_tickets():\n",
    "    tickets = load_tickets()\n",
    "    changed = False\n",
    "\n",
    "    for t in tickets:\n",
    "        if t[\"status\"] == \"open\":\n",
    "            analysis = analyze_ticket(t[\"description\"])\n",
    "            t[\"ai_analysis\"] = analysis\n",
    "            conf = analysis.get(\"confidence\", 0)\n",
    "\n",
    "            if conf >= 85:\n",
    "                t[\"status\"] = \"closed\"\n",
    "            else:\n",
    "                t[\"status\"] = \"need review\"\n",
    "\n",
    "            changed = True\n",
    "\n",
    "    if changed:\n",
    "        save_tickets(tickets)\n",
    "\n",
    "# ---------- STREAMLIT UI ----------\n",
    "st.title(\"ðŸŽ« Automated Ticketing System\")\n",
    "\n",
    "# ðŸ‘‰ Process on page load (runs AFTER the UI renders)\n",
    "auto_process_open_tickets()\n",
    "\n",
    "# ðŸ‘‰ USER INPUT â€” this is where you enter new tickets\n",
    "st.subheader(\"Create a New Ticket\")\n",
    "user_input = st.text_input(\"Enter new ticket description:\")\n",
    "\n",
    "if st.button(\"Create Ticket\"):\n",
    "    if not user_input.strip():\n",
    "        st.error(\"Please enter a ticket description.\")\n",
    "    else:\n",
    "        tickets = load_tickets()\n",
    "        new_no = get_next_ticket_no(tickets)\n",
    "\n",
    "        new_ticket = {\n",
    "            \"ticket_no\": new_no,\n",
    "            \"description\": user_input,\n",
    "            \"status\": \"open\"\n",
    "        }\n",
    "\n",
    "        tickets.append(new_ticket)\n",
    "        save_tickets(tickets)\n",
    "\n",
    "        # Auto process right after creating\n",
    "        auto_process_open_tickets()\n",
    "\n",
    "        st.success(f\"Ticket {new_no} created and processed!\")\n",
    "\n",
    "# (No ticket display, as you requested)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0782bc8f-aa14-4fb7-8bc9-dbdf8c3c8a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run app.py --server.headless true --server.port 8501\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccc612c-5acd-42cd-8ace-ff2f6450622c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
